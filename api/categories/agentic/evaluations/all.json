[{"category":"Agentic","homepage_url":"https://awslabs.github.io/agent-evaluation/","id":"agentic--evaluations--agent-evaluation","logo_url":"http://127.0.0.1:8000/logos/400e4d0634dcd7b05d6b2031efe427761025d0c449189e8bfb4cd7ae797ecc0b.png","name":"Agent Evaluation","subcategory":"Evaluations","description":"A generative AI-powered framework for testing virtual agents.","oss":true,"repositories":[{"url":"https://github.com/awslabs/agent-evaluation","languages":{"Jinja":4438,"Python":113635},"primary":true}]},{"category":"Agentic","homepage_url":"https://deepeval.com/","id":"agentic--evaluations--deepeval","logo_url":"http://127.0.0.1:8000/logos/659882c6f7dcbf109873e1b3229725ddb0519cdff36cacb38c1bb5d378c1cf7a.svg","name":"DeepEval","subcategory":"Evaluations","description":"The LLM Evaluation Framework","oss":true,"repositories":[{"url":"https://github.com/confident-ai/deepeval","languages":{"Python":4709719},"primary":true}]},{"category":"Agentic","homepage_url":"https://github.com/princeton-pli/hal-harness","id":"agentic--evaluations--hal-the-holistic-agent-leaderboard","logo_url":"http://127.0.0.1:8000/logos/c3a0b97f771d5882882322de77ca5682b7dcc01e6c28a09b2d73cb0702b96354.png","name":"HAL: The Holistic Agent Leaderboard","subcategory":"Evaluations","repositories":[{"url":"https://github.com/princeton-pli/hal-harness","languages":{"Dockerfile":990,"Makefile":123,"Python":746191,"Shell":12241},"primary":true}]},{"category":"Agentic","homepage_url":"https://docs.ragas.io/en/stable/","id":"agentic--evaluations--ragas","logo_url":"http://127.0.0.1:8000/logos/9320e9e8326fafb463d4201ef4f4052f49b630c66605d0862f2efcaf0d433193.svg","name":"Ragas","subcategory":"Evaluations","description":"Supercharge Your LLM Application Evaluations ðŸš€","oss":true,"repositories":[{"url":"https://github.com/vibrantlabsai/ragas","languages":{"Dockerfile":199,"Jupyter Notebook":481446,"Makefile":9674,"Python":2394005,"Shell":68},"primary":true}]},{"category":"Agentic","homepage_url":"https://trulens.org","id":"agentic--evaluations--trulens","logo_url":"http://127.0.0.1:8000/logos/b58dc2c325feed13f26e2d5ed493b2ccf2bdb4665037127a7ba23550c6df3ce9.svg","name":"TruLens","subcategory":"Evaluations","description":"Evaluation and Tracking for LLM Experiments and AI Agents","oss":true,"repositories":[{"url":"https://github.com/truera/trulens","languages":{"CSS":942,"HTML":693,"JavaScript":2070,"Jupyter Notebook":334300,"Makefile":12048,"Mako":1555,"Python":3327816,"Shell":2714,"TypeScript":204419},"primary":true}]}]