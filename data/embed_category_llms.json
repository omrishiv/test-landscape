{"classification":{"category":{"name":"LLMs","normalized_name":"llms","subcategories":[{"name":"Serving","normalized_name":"serving"}]}},"foundation":"Agentic Community","items":[{"category":"LLMs","id":"llms--serving--vllm","name":"vLLM","logo":"logos/789d223c86d7884c48ea51f8e799e8c0ce952495186131fcaed24c06292d0e45.svg","subcategory":"Serving","website":"https://vllm.ai/","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","primary_repository_url":"https://github.com/vllm-project/vllm"},{"category":"LLMs","id":"llms--serving--sglang","name":"SGLang","logo":"logos/c801ac352c84d27689070962d2d8bf4d042c369759bac9dfa40d89eac48c027e.png","subcategory":"Serving","website":"https://www.sglang.io/","description":"SGLang is a high-performance serving framework for large language models and multimodal models.","primary_repository_url":"https://github.com/sgl-project/sglang"}]}