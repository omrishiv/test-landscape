{"github_data":{"https://github.com/awslabs/agent-evaluation":{"contributors":{"count":16,"url":"https://github.com/awslabs/agent-evaluation/graphs/contributors"},"description":"A generative AI-powered framework for testing virtual agents.","generated_at":"2026-02-10T17:38:13.120269360Z","latest_commit":{"ts":"2025-12-15T18:10:33Z","url":"https://github.com/awslabs/agent-evaluation/commit/5e8de2d5af022a13e654542278f12791a80f44aa"},"participation_stats":[0,0,0,2,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,1,0,0,0,0,0,0,0,0],"stars":337,"url":"https://github.com/awslabs/agent-evaluation","first_commit":{"ts":"2024-03-19T19:58:28Z","url":"https://github.com/awslabs/agent-evaluation/commit/e9b033ab238c952f1a1976a7cf10dcba26fd1679"},"languages":{"Jinja":4438,"Python":113635},"latest_release":{"ts":"2025-03-31T17:32:41Z","url":"https://github.com/awslabs/agent-evaluation/releases/tag/v0.4.1"},"license":"Apache License 2.0"},"https://github.com/confident-ai/deepeval":{"contributors":{"count":254,"url":"https://github.com/confident-ai/deepeval/graphs/contributors"},"description":"The LLM Evaluation Framework","generated_at":"2026-02-10T17:38:16.286287764Z","latest_commit":{"ts":"2026-02-10T07:12:20Z","url":"https://github.com/confident-ai/deepeval/commit/08d119d6200aebe7c0dd0d802b4faa6e5b3cb1b4"},"participation_stats":[50,54,62,30,43,73,33,46,29,55,71,35,81,58,43,50,61,51,75,87,87,91,126,141,259,197,119,91,122,177,111,170,102,142,193,131,158,103,42,67,17,51,171,165,69,34,26,35,12,44,119,15],"stars":13602,"topics":["evaluation-framework","evaluation-metrics","llm-evaluation","llm-evaluation-framework","llm-evaluation-metrics","python"],"url":"https://github.com/confident-ai/deepeval","first_commit":{"ts":"2023-08-10T06:58:58Z","url":"https://github.com/confident-ai/deepeval/commit/d30c2ccb9bf953c5022a055fc452f78a5482050a"},"languages":{"Python":4709719},"latest_release":{"ts":"2025-12-01T10:52:54Z","url":"https://github.com/confident-ai/deepeval/releases/tag/v3.8.3"},"license":"Apache License 2.0"},"https://github.com/princeton-pli/hal-harness":{"contributors":{"count":19,"url":"https://github.com/princeton-pli/hal-harness/graphs/contributors"},"description":"","generated_at":"2026-02-10T17:38:52.909091174Z","latest_commit":{"ts":"2026-02-05T22:42:46Z","url":"https://github.com/princeton-pli/hal-harness/commit/8ba7948f4dc0175ef4b4d21d47c6ac7420e113e8"},"participation_stats":[0,12,23,0,12,37,23,75,68,64,7,13,3,0,0,0,0,0,0,0,0,0,0,2,6,12,3,0,0,2,2,1,0,5,5,1,1,5,3,2,0,3,0,0,1,1,0,0,0,5,1,3],"stars":223,"url":"https://github.com/princeton-pli/hal-harness","first_commit":{"ts":"2024-07-29T20:23:45Z","url":"https://github.com/princeton-pli/hal-harness/commit/6f10e596ed0bf044ebbde5d6df4772a1e8d83450"},"languages":{"Dockerfile":990,"Makefile":123,"Python":746191,"Shell":12241}},"https://github.com/truera/trulens":{"contributors":{"count":67,"url":"https://github.com/truera/trulens/graphs/contributors"},"description":"Evaluation and Tracking for LLM Experiments and AI Agents","generated_at":"2026-02-10T17:39:00.625405023Z","latest_commit":{"ts":"2026-02-07T18:21:18Z","url":"https://github.com/truera/trulens/commit/8e710e4cb81cb797ac140c81cb51ddf662b4b872"},"participation_stats":[9,15,22,10,6,8,5,6,15,17,5,13,15,10,13,33,16,6,20,14,5,9,8,14,6,10,4,12,7,7,9,9,4,12,6,5,3,2,5,4,4,0,0,4,2,0,0,3,4,3,7,2],"stars":3083,"topics":["agent-evaluation","agentops","ai-agents","ai-monitoring","ai-observability","evals","explainable-ml","llm-eval","llm-evaluation","llmops","llms","machine-learning","neural-networks"],"url":"https://github.com/truera/trulens","first_commit":{"ts":"2020-11-13T17:15:50Z","url":"https://github.com/truera/trulens/commit/657f6042a714845cd369872037d8f942672556fa"},"languages":{"CSS":942,"HTML":693,"JavaScript":2070,"Jupyter Notebook":334300,"Makefile":12048,"Mako":1555,"Python":3327816,"Shell":2714,"TypeScript":204419},"latest_release":{"ts":"2026-02-04T20:34:59Z","url":"https://github.com/truera/trulens/releases/tag/trulens-2.6.0"},"license":"MIT License"},"https://github.com/vibrantlabsai/ragas":{"contributors":{"count":245,"url":"https://github.com/vibrantlabsai/ragas/graphs/contributors"},"description":"Supercharge Your LLM Application Evaluations ðŸš€","generated_at":"2026-02-10T17:39:02.092563569Z","latest_commit":{"ts":"2026-01-31T06:51:59Z","url":"https://github.com/vibrantlabsai/ragas/commit/2b38724972a18f77b51247657654b3e74a615a30"},"participation_stats":[5,5,5,2,1,1,1,5,1,2,5,2,9,3,4,2,0,1,5,1,3,2,11,2,2,3,18,34,23,14,8,24,16,11,9,10,9,7,12,9,9,11,8,21,18,5,3,5,6,1,1,0],"stars":12568,"topics":["evaluation","llm","llmops"],"url":"https://github.com/vibrantlabsai/ragas","first_commit":{"ts":"2023-05-08T17:48:04Z","url":"https://github.com/vibrantlabsai/ragas/commit/5b2a57e8d40739b8c0299c92143cb3d27faa2b26"},"languages":{"Dockerfile":199,"Jupyter Notebook":481446,"Makefile":9674,"Python":2394005,"Shell":68},"latest_release":{"ts":"2026-01-13T17:47:29Z","url":"https://github.com/vibrantlabsai/ragas/releases/tag/v0.4.3"},"license":"Apache License 2.0"}},"items":[{"category":"Agentic","homepage_url":"https://trulens.org","id":"agentic--evaluations--trulens","logo":"logos/b58dc2c325feed13f26e2d5ed493b2ccf2bdb4665037127a7ba23550c6df3ce9.svg","name":"TruLens","subcategory":"Evaluations","website":"https://trulens.org","oss":true,"repositories":[{"url":"https://github.com/truera/trulens","primary":true}]},{"category":"Agentic","homepage_url":"https://github.com/princeton-pli/hal-harness","id":"agentic--evaluations--hal-the-holistic-agent-leaderboard","logo":"logos/c3a0b97f771d5882882322de77ca5682b7dcc01e6c28a09b2d73cb0702b96354.png","name":"HAL: The Holistic Agent Leaderboard","subcategory":"Evaluations","website":"https://github.com/princeton-pli/hal-harness","repositories":[{"url":"https://github.com/princeton-pli/hal-harness","primary":true}]},{"category":"Agentic","homepage_url":"https://awslabs.github.io/agent-evaluation/","id":"agentic--evaluations--agent-evaluation","logo":"logos/400e4d0634dcd7b05d6b2031efe427761025d0c449189e8bfb4cd7ae797ecc0b.png","name":"Agent Evaluation","subcategory":"Evaluations","website":"https://awslabs.github.io/agent-evaluation/","oss":true,"repositories":[{"url":"https://github.com/awslabs/agent-evaluation","primary":true}]},{"category":"Agentic","homepage_url":"https://docs.ragas.io/en/stable/","id":"agentic--evaluations--ragas","logo":"logos/9320e9e8326fafb463d4201ef4f4052f49b630c66605d0862f2efcaf0d433193.svg","name":"Ragas","subcategory":"Evaluations","website":"https://docs.ragas.io/en/stable/","oss":true,"repositories":[{"url":"https://github.com/vibrantlabsai/ragas","primary":true}]},{"category":"Agentic","homepage_url":"https://deepeval.com/","id":"agentic--evaluations--deepeval","logo":"logos/659882c6f7dcbf109873e1b3229725ddb0519cdff36cacb38c1bb5d378c1cf7a.svg","name":"DeepEval","subcategory":"Evaluations","website":"https://deepeval.com/","oss":true,"repositories":[{"url":"https://github.com/confident-ai/deepeval","primary":true}]}]}