{"github_data":{"https://github.com/sgl-project/sglang":{"contributors":{"count":1074,"url":"https://github.com/sgl-project/sglang/graphs/contributors"},"description":"SGLang is a high-performance serving framework for large language models and multimodal models.","generated_at":"2026-02-10T17:51:51.815701578Z","latest_commit":{"ts":"2026-02-10T17:17:40Z","url":"https://github.com/sgl-project/sglang/commit/2d38b8aca016a1702eef7e6fbd4c201937abda8a"},"participation_stats":[63,53,75,128,135,59,121,50,114,134,119,79,93,79,102,103,87,108,87,81,91,65,97,119,145,178,149,142,124,156,184,123,134,134,176,181,204,187,214,259,208,206,233,302,223,213,237,272,180,212,186,138],"stars":23481,"topics":["attention","blackwell","cuda","deepseek","diffusion","glm","gpt-oss","inference","llama","llm","minimax","moe","qwen","qwen-image","reinforcement-learning","transformer","vlm","wan"],"url":"https://github.com/sgl-project/sglang","first_commit":{"ts":"2023-10-09T22:41:15Z","url":"https://github.com/sgl-project/sglang/commit/f6d40df0ee1e1fc53db3edc04bf90575f221cf23"},"languages":{"C":100244,"C++":1365286,"CMake":32407,"Cuda":1580046,"Dockerfile":60409,"Go":105506,"HIP":15490,"Jinja":1205,"Jupyter Notebook":7292,"Makefile":23168,"Python":24984214,"Rust":3095858,"Shell":151167,"Vim Script":914},"latest_release":{"ts":"2026-01-23T22:09:28Z","url":"https://github.com/sgl-project/sglang/releases/tag/v0.5.8"},"license":"Apache License 2.0"},"https://github.com/vllm-project/vllm":{"contributors":{"count":2178,"url":"https://github.com/vllm-project/vllm/graphs/contributors"},"description":"A high-throughput and memory-efficient inference and serving engine for LLMs","generated_at":"2026-02-10T17:52:00.961982928Z","latest_commit":{"ts":"2026-02-10T16:55:22Z","url":"https://github.com/vllm-project/vllm/commit/a2443de5fa4a0605607f6c3d9219022c7f6ac480"},"participation_stats":[132,130,126,163,165,143,159,153,146,107,192,154,149,157,165,137,141,125,113,109,146,173,155,224,197,199,198,203,205,154,248,267,247,197,201,214,167,170,188,244,246,205,227,222,190,107,94,264,167,205,229,224],"stars":69986,"topics":["amd","blackwell","cuda","deepseek","deepseek-v3","gpt","gpt-oss","inference","kimi","llama","llm","llm-serving","model-serving","moe","openai","pytorch","qwen","qwen3","tpu","transformer"],"url":"https://github.com/vllm-project/vllm","first_commit":{"ts":"2023-02-09T11:24:15Z","url":"https://github.com/vllm-project/vllm/commit/e7d9d9c08c79b386f6d0477e87b77a572390317d"},"languages":{"C":95214,"C++":1251440,"CMake":98243,"Cuda":2010123,"Dockerfile":35685,"HCL":1731,"Jinja":6380,"Python":26045994,"Shell":255325},"latest_release":{"ts":"2026-02-04T20:48:08Z","url":"https://github.com/vllm-project/vllm/releases/tag/v0.15.1"},"license":"Apache License 2.0"}},"items":[{"category":"LLMs","homepage_url":"https://vllm.ai/","id":"llms--serving--vllm","logo":"logos/789d223c86d7884c48ea51f8e799e8c0ce952495186131fcaed24c06292d0e45.svg","name":"vLLM","subcategory":"Serving","website":"https://vllm.ai/","oss":true,"repositories":[{"url":"https://github.com/vllm-project/vllm","primary":true}]},{"category":"LLMs","homepage_url":"https://www.sglang.io/","id":"llms--serving--sglang","logo":"logos/c801ac352c84d27689070962d2d8bf4d042c369759bac9dfa40d89eac48c027e.png","name":"SGLang","subcategory":"Serving","website":"https://www.sglang.io/","oss":true,"repositories":[{"url":"https://github.com/sgl-project/sglang","primary":true}]}]}